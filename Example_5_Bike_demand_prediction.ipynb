{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example_5 Bike demand prediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPp+RptsaqVQ9ZnyuT/XCfm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KangSangKyu/BOOKSTUDY_Python-Machine-Learning-Perfect-Guide/blob/main/Example_5_Bike_demand_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVwJzwFOeWZG"
      },
      "source": [
        "# Bike demand prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tysEb83KTxD1"
      },
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0kZ6u84UifT"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "\n",
        "bike_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/train_1204.csv')\n",
        "\n",
        "print(bike_df.shape)\n",
        "bike_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVBZEJo2U866"
      },
      "source": [
        "bike_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUa09SrBU-14"
      },
      "source": [
        "# 문자열 datetime 타입으로 변경 \n",
        "\n",
        "bike_df['datetime'] = bike_df.datetime.apply(pd.to_datetime)\n",
        "\n",
        "# datetime 타입에서 년, 월, 일, 시간 추출\n",
        "\n",
        "bike_df['year'] = bike_df.datetime.apply(lambda x : x.year)\n",
        "bike_df['month'] = bike_df.datetime.apply(lambda x : x.month)\n",
        "bike_df['day'] = bike_df.datetime.apply(lambda x : x.day)\n",
        "bike_df['hour'] = bike_df.datetime.apply(lambda x : x.hour)\n",
        "\n",
        "bike_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiG4-RyVU_2u"
      },
      "source": [
        "# 칼럼 삭제 \n",
        "\n",
        "drop_columns = ['datetime', 'casual', 'registered']\n",
        "\n",
        "bike_df.drop(drop_columns, axis=1, inplace=True)\n",
        "bike_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwdt94TDVBZN"
      },
      "source": [
        "# RMSLE, RMSE, MSE 를 구하는 함수 \n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# log 값 반환 시 NaN 등의 이슈로 log()가 아닌 log1p()를 이용해 RMSE 계산 \n",
        "\n",
        "def rmsle(y, pred):\n",
        "    log_y = np.log1p(y)\n",
        "    log_pred = np.log1p(pred)\n",
        "    squared_error = (log_y - log_pred) ** 2\n",
        "    rmsle = np.sqrt(np.mean(squared_error))\n",
        "    \n",
        "    return rmsle\n",
        "\n",
        "# 사이킷런의 mean_square_error()를 이용해 RMSE 계산 \n",
        "\n",
        "def rmse(y, pred):\n",
        "    return np.sqrt(mean_squared_error(y, pred))\n",
        "\n",
        "# MSE, RMSE, RMSLE 를 모두 계산 \n",
        "\n",
        "def evaluate_regr(y, pred):\n",
        "    rmsle_val = rmsle(y, pred)\n",
        "    rmse_val = rmse(y, pred)\n",
        "    \n",
        "    # MSE는 사이킷런의 mean_absolute_error()로 계산\n",
        "    mse_val = mean_absolute_error(y, pred)\n",
        "    \n",
        "    print('RMSLE: {0:.3f}, RMSE: {1:3f}, MSE: {2:3f}'.format(rmsle_val, rmse_val, mse_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ02HrfpVCj3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "\n",
        "y_target = bike_df['count']\n",
        "X_features = bike_df.drop(['count'], axis=1, inplace=False)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3, random_state=0)\n",
        "\n",
        "lr_reg = LinearRegression()\n",
        "lr_reg.fit(X_train, y_train)\n",
        "pred = lr_reg.predict(X_test)\n",
        "\n",
        "evaluate_regr(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OC-cu7VUVD_W"
      },
      "source": [
        "def get_top_error_data(y_test, pred, n_tops=5):\n",
        "    \n",
        "    # 데이터프레임의 칼럼으로 실제 대여 횟수(count)와 예측값을 서로 비교할 수 있도록 생성 \n",
        "    result_df = pd.DataFrame(y_test.values, columns=['real_count'])\n",
        "    result_df['predicted_count'] = np.round(pred)\n",
        "    result_df['diff'] = np.abs(result_df['real_count'] - result_df['predicted_count'])\n",
        "    \n",
        "    # 예측값과 실제 값이 가장 큰 데이터 순으로 출력 \n",
        "    print(result_df.sort_values('diff', ascending=False)[:n_tops])\n",
        "    \n",
        "get_top_error_data(y_test, pred, n_tops=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvvxg24AVE_l"
      },
      "source": [
        "y_target.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WJHTIbCVGpv"
      },
      "source": [
        "y_log_transform = np.log1p(y_target)\n",
        "y_log_transform.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJPo2q_WVH8b"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 타깃 칼럼인 count 값을 log1p로 로그 변환 \n",
        "\n",
        "y_target_log = np.log1p(y_target)\n",
        "\n",
        "# 로그 변환된 y_target_log를 반영해 학습 / 테스트 세트 분할 \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target_log, test_size=0.3, random_state=0)\n",
        "\n",
        "lr_reg = LinearRegression()\n",
        "lr_reg.fit(X_train, y_train)\n",
        "pred = lr_reg.predict(X_test)\n",
        "\n",
        "# 테스트 데이터 세트의 Target 값은 로그 변환됐으므로 다시 expm1 을 이용해 원래 스케일로 변환 \n",
        "\n",
        "y_test_exp = np.expm1(y_test)\n",
        "\n",
        "# 예측값 역시 로그 변환된 타깃 기반으로 학습돼 예측했으므로 다시 expm1 으로 스케일 변환 \n",
        "\n",
        "pred_exp = np.expm1(pred)\n",
        "\n",
        "evaluate_regr(y_test_exp, pred_exp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA0bheTKVJUP"
      },
      "source": [
        "# 각 회귀 계수의 값 시각화 하기 \n",
        "\n",
        "coef = pd.Series(lr_reg.coef_, index=X_features.columns)\n",
        "coef_sort = coef.sort_values(ascending=False)\n",
        "sns.barplot(x=coef_sort.values, y=coef_sort.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqaFvNMOVKmE"
      },
      "source": [
        "# 'year', 'month', 'hour', 'season', 'wather' 피처를 원-핫 인코딩\n",
        "\n",
        "X_features_ohe = pd.get_dummies(X_features, columns=['year', 'month', 'hour', 'holiday', 'workingday', 'season', 'weather'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XVXcsaVVMDv"
      },
      "source": [
        "# 원-핫 인코딩이 적용된 피처 데이터 세트 기반으로 학습 / 예측 데이터 분할 \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features_ohe, y_target_log, test_size=0.3, random_state=0)\n",
        "\n",
        "# 모델과 학습 / 테스트 데이터 세트를 입력하면 성능 평가 수치를 반환 \n",
        "\n",
        "def get_model_predict(model, X_train, X_test, y_train, y_test, is_expm1=False):\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    if is_expm1 :\n",
        "        y_test = np.expm1(y_test)\n",
        "        pred = np.expm1(pred)\n",
        "    print('###', model.__class__.__name__, '###')\n",
        "    evaluate_regr(y_test, pred)\n",
        "    \n",
        "# end of function get_model_predict\n",
        "\n",
        "# 모델별로 평가 수행 \n",
        "\n",
        "lr_reg = LinearRegression()\n",
        "ridge_reg = Ridge(alpha=10)\n",
        "lasso_reg = Lasso(alpha=0.01)\n",
        "\n",
        "for model in [lr_reg, ridge_reg, lasso_reg]:\n",
        "    get_model_predict(model, X_train, X_test, y_train, y_test, is_expm1=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QN55bwhVNaG"
      },
      "source": [
        "coef = pd.Series(lr_reg.coef_, index=X_features_ohe.columns)\n",
        "coef_sort = coef.sort_values(ascending=False)[:10]\n",
        "sns.barplot(x=coef_sort.values, y=coef_sort.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv2k29QgVO27"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# 랜덤 포레스트 GBM, XGBoost, LightGBM 모델별로 평가 수행 \n",
        "\n",
        "rf_reg = RandomForestRegressor(n_estimators=500)\n",
        "gbm_reg = GradientBoostingRegressor(n_estimators=500)\n",
        "xgb_reg = XGBRegressor(n_estimators=500)\n",
        "lgbm_reg = LGBMRegressor(n_estimators=500)\n",
        "\n",
        "for model in[rf_reg, gbm_reg, xgb_reg, lgbm_reg]:\n",
        "    get_model_predict(model, X_train, X_test, y_train, y_test, is_expm1=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAiwnQ2MVQKG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}