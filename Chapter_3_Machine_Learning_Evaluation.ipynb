{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter_3_Machine Learning Evaluation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNA71RFkLt9iCs0BIo9gyFQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KangSangKyu/BOOKSTUDY_Python-Machine-Learning-Perfect-Guide/blob/main/Chapter_3_Machine_Learning_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdvD6DLUZQhh"
      },
      "source": [
        "# Machine Learning Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DkcX2XfdA0-"
      },
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeuB2fwBNwC8"
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyDummyClassifier(BaseEstimator):\n",
        "    \n",
        "    # fit() 메서드는 아무것도 학습하지 않음. \n",
        "    def fit(self, X, y=None):\n",
        "        pass\n",
        "    \n",
        "    # predict() 메서드는 단순히 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측함. \n",
        "    \n",
        "    def predict(self, X):\n",
        "        pred = np.zeros((X.shape[0], 1))\n",
        "        for i in range (X.shape[0]):\n",
        "            if X['Sex'].iloc[i] == 1:\n",
        "                pred[i] = 0\n",
        "            else :\n",
        "                pred[i] = 1\n",
        "                \n",
        "        return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEq2ZJ5oN3m-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터 / 테스트 데이터 분할.\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Null 처리 함수\n",
        "\n",
        "def fillna(df):\n",
        "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "    df['Cabin'].fillna('N', inplace=True)\n",
        "    df['Embarked'].fillna('N', inplace=True)\n",
        "    df['Fare'].fillna(0, inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# 머신러닝 알고리즘에 불필요한 속성 제거 \n",
        "\n",
        "def drop_features(df):\n",
        "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 레이블 인코딩 수행 \n",
        "\n",
        "def format_features(df):\n",
        "    df['Cabin'] = df['Cabin'].str[:1]\n",
        "    features = ['Cabin', 'Sex', 'Embarked']\n",
        "    \n",
        "    for feature in features:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(df[feature])\n",
        "        df[feature] = le.transform(df[feature])\n",
        "        \n",
        "    return df\n",
        "\n",
        "# 앞에서 설정한 데이터 전처리 함수 호출 \n",
        "\n",
        "def transform_features(df):\n",
        "    df = fillna(df)\n",
        "    df = drop_features(df)\n",
        "    df = format_features(df)\n",
        "    return df\n",
        "\n",
        "titanic_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/titanic_train.csv')\n",
        "\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0)\n",
        "\n",
        "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가를 수행. \n",
        "\n",
        "myclf = MyDummyClassifier()\n",
        "myclf.fit(X_train, y_train)\n",
        "\n",
        "mypredictions = myclf.predict(X_test)\n",
        "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))\n",
        "\n",
        "## 단순한 알고리즘으로도 어느정도 높은 정확도가 나올 수있기 때문에 accuracy만을 평가지표로 사용하면 안된다.\n",
        "## 또한 불균형한 레이블 값 분포에 ML 모델을 적용하며 Accuracy가 높게 나타남으로 주의가 필요하다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIkZy4tJN5qj"
      },
      "source": [
        "# confusion matrix, accuracy, precision, recall 등의 평가지표를 한꺼번에 호출하는 함수 \n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "def get_clf_eval(y_test, pred):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    \n",
        "    print('오차 행렬\\n')\n",
        "    print(confusion)\n",
        "    print('\\n정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy,precision, recall))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJw5IAeVPm5e"
      },
      "source": [
        "# 로지스틱 회귀 기반으로 타이타닉 생존자 예측 \n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터 / 테스트 데이터 분할 \n",
        "\n",
        "titanic_df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/titanic_train.csv')\n",
        "\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
        "\n",
        "X_titanic_df = transform_features(X_titanic_df)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train, y_train)\n",
        "pred = lr_clf.predict(X_test)\n",
        "\n",
        "get_clf_eval(y_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f8sCwQtPoau"
      },
      "source": [
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "pred = lr_clf.predict(X_test)\n",
        "\n",
        "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
        "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
        "\n",
        "# 예측 확률 array와 예측 결과값 array를 병합해 예측 확률과 결과값을 확인 \n",
        "\n",
        "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
        "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiK5AX5_PzpG"
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "X = [[1,-1,2],\n",
        "     [2,0,0],\n",
        "     [0,1.1,1.2]]\n",
        "\n",
        "# X의 개별 원소들이 threshold값보다 같거나 작으면 0을, 크면 1을 반환 \n",
        "\n",
        "binarizer = Binarizer(threshold=1.1)\n",
        "print(binarizer.fit_transform(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3W0_OxSP09w"
      },
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "# Binarizer의 threshold 설정값. 분류 결정 임계값임. \n",
        "\n",
        "custom_threshold = 0.5\n",
        "\n",
        "# predict_proba() 반환값의 두 번째 칼럼, 즉 positive 클래스 칼럼 하나만 추출해 Binarizer를 적용 \n",
        "\n",
        "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
        "\n",
        "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
        "custom_predict = binarizer.transform(pred_proba_1)\n",
        "\n",
        "get_clf_eval(y_test, custom_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUsoHgWeP2JG"
      },
      "source": [
        "# Binarizer의 threshold 설정값을 0.4로 설정. 즉 분류 결정 임계값을 0.5에서 0.4로 낮춤\n",
        "\n",
        "custom_threshold = 0.4\n",
        "\n",
        "pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
        "\n",
        "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1)\n",
        "custom_predict = binarizer.transform(pred_proba_1)\n",
        "\n",
        "get_clf_eval(y_test, custom_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgYl4-kpP3Po"
      },
      "source": [
        "# 임계값을 조정하며 평가지표를 반환하는 함수\n",
        "\n",
        "# 테스트를 수행할 모든 임계값 리스트 객체 생성 \n",
        "\n",
        "thresholds =[0.4, 0.45, 0.50, 0.55, 0.60]\n",
        "\n",
        "def get_eval_by_treshold(y_test, pred_proba_c1, thresholds):\n",
        "    \n",
        "    # thresholds list 객체 내의 값을 차례로 iteration하면서 evaluation 수행 \n",
        "    \n",
        "    for custom_threshold in thresholds:\n",
        "        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)\n",
        "        custom_predict = binarizer.transform(pred_proba_c1)\n",
        "        print('임계값:', custom_threshold)\n",
        "        get_clf_eval(y_test, custom_predict)\n",
        "        \n",
        "get_eval_by_treshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbVN_NyiP4kz"
      },
      "source": [
        "# precision_recall_curve()를 이용한 예측 모델의 임계값별 정밀도와 재현율 구하기 \n",
        "\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# 레이블 값이 1일 때의 예측 확률을 추출\n",
        "\n",
        "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "# 실제값 데이터 세트와 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 \n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
        "print('반환된 분류 결정 임계값 배열의 Shape:', thresholds.shape)\n",
        "\n",
        "# 반환된 임계값 배열 로우가 147건 이므로 샘플로 10건만 추출하되, 임계값을 15 step으로 추출 \n",
        "\n",
        "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
        "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
        "print('샘플용 10개의 임계값:', np.round(thresholds[thr_index], 2))\n",
        "\n",
        "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
        "\n",
        "print('샘플 임계값별 정밀도:', np.round(precisions[thr_index], 3))\n",
        "print('샘플 임계값별 재현율:', np.round(recalls[thr_index], 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2DtezPlP6JI"
      },
      "source": [
        "# 임계값에 따른 정밀도와 재현율 곡선 시각화 \n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
        "    # threshold ndarray와 threshold에 따른 정밀도, 재현율 ndarray 추출.\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
        "    \n",
        "    # X축을 threshold값으로, Y축은 정밀로, 재현율 값으로 각각 plot 수행. 정밀도는 점선으로 표시 \n",
        "    plt.figure(figsize=(8,6))\n",
        "    threshold_boundary = thresholds.shape[0]\n",
        "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
        "    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
        "    \n",
        "    # threshold 값 X축의 Scale을 0.1 단위로 변경 \n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
        "    \n",
        "    # X축, Y축 label과 legend, 그리고 grid 설정 \n",
        "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
        "    plt.legend(); plt.grid()\n",
        "    plt.show()\n",
        "    \n",
        "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeSvH5nXP7Vv"
      },
      "source": [
        "# F1 Score\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_test, pred)\n",
        "print('F1 스코어: {0:.4f}'.format(f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IALCB5boP8mK"
      },
      "source": [
        "# F1 Score를 포함한 임계값에 따른 평가지표 반환 함수 \n",
        "\n",
        "def get_clf_eval(y_test, pred):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    \n",
        "    # F1 Score 추가\n",
        "    f1 = f1_score(y_test, pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    \n",
        "    # F1 Score print 추가 \n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}'.format(accuracy, precision, recall, f1))\n",
        "    \n",
        "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "get_eval_by_treshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TFprTG5P9vK"
      },
      "source": [
        "# ROC 곡선과 AUC \n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# 레이블 값이 1일 때의 예측 확률을 추출\n",
        "\n",
        "pred_proba_class1 = lr_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)\n",
        "\n",
        "# 반환된 임계값 배열 로우가 47건 이므로 샘플로 10건만 추출하되, 임계값을 5 Step으로 추출 \n",
        "\n",
        "thr_index = np.arange(0, thresholds.shape[0], 5)\n",
        "\n",
        "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
        "print('샘플용 10개의 임계값:', np.round(thresholds[thr_index], 2))\n",
        "\n",
        "# 5 Step 단위로 추출된 임계값에 따른 FPR, TPR 값 \n",
        "\n",
        "print('샘플 임계값별 FPR:', np.round(fprs[thr_index], 3))\n",
        "print('샘플 임계값별 TPR:', np.round(tprs[thr_index], 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meFh-NiBQBFC"
      },
      "source": [
        "# ROC 곡선 시각화 \n",
        "\n",
        "def roc_curve_plot(y_test, pred_proba_c1):\n",
        "    \n",
        "    # 임계값에 따른 FPR, TPR 값을 반환받음 \n",
        "    fprs, tprs, thresholds = roc_curve(y_test, pred_proba_c1)\n",
        "    \n",
        "    # ROC 곡선을 그래프 곡선으로 그림 \n",
        "    plt.plot(fprs, tprs, label='ROC')\n",
        "    \n",
        "    # 가운데 대각선 직선을 그림 \n",
        "    plt.plot([0,1], [0,1], 'k--', label='Random')\n",
        "    \n",
        "    # FPR X 축의 Scale을 0.1 단위로 변경, X, Y 축 명 설정 등 \n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
        "    plt.xlim(0,1); plt.ylim(0,1)\n",
        "    plt.xlabel('FPR(1 - Sensitivity)'); plt.ylabel('TPR(Recall)')\n",
        "    plt.legend()\n",
        "    \n",
        "roc_curve_plot(y_test, pred_proba[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m33xrh9lQCL_"
      },
      "source": [
        "# ROC AUC 구하기 \n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "pred = lr_clf.predict(X_test)\n",
        "roc_score = roc_auc_score(y_test, pred)\n",
        "\n",
        "print('ROC AUC 값: {0:.4f}'.format(roc_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAZryVNGQDdR"
      },
      "source": [
        "# 임계값에 따른 평가지표 반환 함수 (정확도, 정밀도, 재현율, F1, ROC_AUC)\n",
        "\n",
        "def get_clf_eval(y_test, pred):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    \n",
        "    # F1 Score 추가\n",
        "    f1 = f1_score(y_test, pred)\n",
        "    \n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    \n",
        "    # ROC AUC 추가\n",
        "    ROC_AUC = roc_auc_score(y_test, pred)\n",
        "    \n",
        "    # ROC AUC print 추가 \n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, ROC_AUC: {4:.4f}'.format(accuracy, precision, recall, f1, ROC_AUC))\n",
        "    \n",
        "thresholds = [0.4, 0.45, 0.50, 0.55, 0.60]\n",
        "pred_proba = lr_clf.predict_proba(X_test)\n",
        "get_eval_by_treshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}