{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example_3_Credit Card Fraud Detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6HTHVx8kBbq5mcfBnmiN2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KangSangKyu/BOOKSTUDY_Python-Machine-Learning-Perfect-Guide/blob/main/Example_3_Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdvD6DLUZQhh"
      },
      "source": [
        "# Example 캐글 신용카드 사기 검출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avHqtceVoSrO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "card_df = pd.read_csv('./creditcard.csv')\n",
        "card_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUp2CyAEoS05"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 인자로 입력받은 데이터프레임을 복사한 뒤 Time 칼럼만 삭제하고 복사된 데이터프레임 반환 \n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "    df_copy = df.copy()\n",
        "    df_copy.drop('Time', axis=1, inplace=True)\n",
        "    return df_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL5IIyceoxfc"
      },
      "source": [
        "# 사전 데이터 가공 후 학습과 테스트 데이터 세트를 반환하는 함수 \n",
        "\n",
        "def get_train_test_dataset(df=None):\n",
        "    \n",
        "    # 인자로 입력된 데이터프레임의 사전 데이터 가공이 완료된 복사 데이터프레임 반환 \n",
        "    df_copy = get_preprocessed_df(df)\n",
        "    \n",
        "    # 데이터프레임의 맨 마지막 칼럼이 레이블, 나머지는 피처들 \n",
        "    X_features = df_copy.iloc[:,:-1]\n",
        "    y_target = df_copy.iloc[:,-1]\n",
        "    \n",
        "    # train_test_split() 으로 학습과 테스트 데이터 분할 stratify=y_target으로 Stratified 기반 분할 \n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3, random_state=0, stratify=y_target)\n",
        "    \n",
        "    # 학습과 테스트 데이터 세트 반환 \n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvuNUTEcoxiB"
      },
      "source": [
        "# 생성한 학습 데이터 세트와 테스트 데이터 세트의 레이블 값 비율을 백분율로 환산해서 비율 확인 \n",
        "\n",
        "print('학습 데이터 레이블 값 비율\\n')\n",
        "print(y_train.value_counts() / y_train.shape[0] * 100)\n",
        "print('\\n테스트 데이터 레이블 값 비율\\n')\n",
        "print(y_test.value_counts() / y_test.shape[0] * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft4h0nefoxkl"
      },
      "source": [
        "# 로지스틱 회귀 모형 적용 \n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_pred = lr_clf.predict(X_test)\n",
        "\n",
        "# 3장에서 사용한 get_clf_eval() 함수를 이용해 평가 수행 \n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
        "\n",
        "def get_clf_eval(y_test, pred):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    f1 = f1_score(y_test, pred)\n",
        "    ROC_AUC = roc_auc_score(y_test, pred)\n",
        "\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "  \n",
        "    # ROC AUC print 추가 \n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, ROC_AUC: {4:.4f}'.format(accuracy, precision, recall, f1, ROC_AUC))\n",
        "\n",
        "get_clf_eval(y_test, lr_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RvUPJsxoxnG"
      },
      "source": [
        "# 인자로 사이킷런의 Estimator 객체와 학습/테스트 데이터 세트를 입력 받아서 학습/예측/평가 수행 \n",
        "\n",
        "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
        "    model.fit(ftr_train, tgt_train)\n",
        "    pred = model.predict(ftr_test)\n",
        "    get_clf_eval(tgt_test, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp4AbMJeo13P"
      },
      "source": [
        "# LGBM으로 모델 학습 후 별도의 테스트 데이터 세트에서 예측 평가 수행 \n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEMZFQDTo2Ax"
      },
      "source": [
        "# amount 피처의 분포도 확인 \n",
        "\n",
        "import seaborn as sns \n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.xticks(range(0,30000,1000), rotation=60)\n",
        "sns.distplot(card_df['Amount'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA-dV8iJo2Em"
      },
      "source": [
        "# 사이킷런의 StandardScaler를 이용해 정규 분포 형태로 Amount 피처값 변환하는 로직으로 수정 \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "    df_copy = df.copy()\n",
        "    scaler = StandardScaler()\n",
        "    amount_n = scaler.fit_transform(df_copy['Amount'].values.reshape(-1,1))\n",
        "    \n",
        "    # 변환된 Amount를 Amount_Scaled로 피처명 변경후 데이터프레임 맨 앞 칼럼으로 입력 \n",
        "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
        "    \n",
        "    # 기존 Time, Amount 피처 삭제 \n",
        "    df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "    return df_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g49Iyss1o5WZ"
      },
      "source": [
        "# Amount를 정규 분포 형태로 변환 후 로지스틱 회귀 및 LGBM 수행 \n",
        "\n",
        "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
        "\n",
        "print('### 로지스틱 회귀 예측 성능 ###')\n",
        "lr_clf = LogisticRegression()\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
        "    \n",
        "print('### LightGBM 예측 성능 ###')\n",
        "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCJvI4uCo5Zk"
      },
      "source": [
        "# Amount 피처에 로그변환 적용 \n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "    df_copy = df.copy()\n",
        "    \n",
        "    # 넘파이의 log1p()를 이용해 Amount를 로그 변환 \n",
        "    amount_n = np.log1p(df_copy['Amount'])\n",
        "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
        "    df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "    return df_copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc2OZA3Ao7hZ"
      },
      "source": [
        "# Amount를 로그 변환 후 로지스틱 회귀 및 LGBM 수행 \n",
        "\n",
        "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
        "\n",
        "print('### 로지스틱 회귀 예측 성능 ###')\n",
        "lr_clf = LogisticRegression()\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
        "    \n",
        "print('### LightGBM 예측 성능 ###')\n",
        "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyOl2nvao7oc"
      },
      "source": [
        "# 이상치 데이터 제거 후 모델 학습/예측/평가 \n",
        "# 각 피처별로 상관관계 시각화 \n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "corr = card_df.corr()\n",
        "sns.heatmap(corr, cmap='RdBu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VojO8leo9nz"
      },
      "source": [
        "# IQR * 1.5 의 Outlier를 검출하는 함수 \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "def get_outlier(df=None, column=None, weight=1.5):\n",
        "    \n",
        "    # fraud에 해당하는 column 데이터만 추출, 1/4 분위와 3/4 분위 지점을 np.percentile로 구함 \n",
        "    fraud = df[df['Class'] == 1][column]\n",
        "    quantile_25 = np.percentile(fraud.values, 25)\n",
        "    quantile_75 = np.percentile(fraud.values, 75)\n",
        "    \n",
        "    # IQR을 구하고, IQR에 1.5를 곱해서 최댓값과 최솟값 지점을 구함 \n",
        "    iqr = quantile_75 - quantile_25\n",
        "    iqr_weight = iqr * weight\n",
        "    lowest_val = quantile_25 - iqr_weight\n",
        "    highest_val = quantile_75 + iqr_weight\n",
        "    \n",
        "    # 최대값보다 크거나, 최솟값보다 작은 값을 이상치 데이터로 설정하고 데이터프레임 index 반환 \n",
        "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n",
        "    \n",
        "    return outlier_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92G-mKh5o-4j"
      },
      "source": [
        "outlier_index = get_outlier(df=card_df, column='V14', weight=1.5)\n",
        "\n",
        "print('이상치의 데이터 인덱스:', outlier_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM2Z620Jo-8f"
      },
      "source": [
        "# get_proprecessed_df()를 로그변환 후 V14 피처의 이상치 데이터를 삭제하는 로직으로 변경 후 로지스틱/LGBM 학습/예측/평가 \n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "    df_copy = df.copy()\n",
        "    amount_n = np.log1p(df_copy['Amount'])\n",
        "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
        "    df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "    \n",
        "    # 이상치 삭제하는 로직 추가 \n",
        "    outlier_index = get_outlier(df=df_copy, column='V14', weight=1.5)\n",
        "    df_copy.drop(outlier_index, axis=0, inplace=True)\n",
        "    \n",
        "    return df_copy\n",
        "\n",
        "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
        "\n",
        "print('### 로지스틱 회귀 예측 성능 ###')\n",
        "lr_clf = LogisticRegression()\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)\n",
        "    \n",
        "print('### LightGBM 예측 성능 ###')\n",
        "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvdH4dsopBJ5"
      },
      "source": [
        "# SMOTE 오버 샘플링 적용 후 모델 학습/예측/평가 \n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=0)\n",
        "\n",
        "X_train_over, y_train_over = smote.fit_sample(X_train, y_train)\n",
        "\n",
        "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트:', X_train.shape, y_train.shape)\n",
        "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트:', X_train_over.shape, y_train_over.shape)\n",
        "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(y_train_over).value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVFy2MygpBPJ"
      },
      "source": [
        "lr_clf = LogisticRegression()\n",
        "\n",
        "# ftr_train과 tgt_train 인자값이 SMOTE 증식된 X_train_over과 y_train_over로 변경됨에 유의 \n",
        "\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train_over, ftr_test=X_test, tgt_train=y_train_over, tgt_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNDVqz_IpDSY"
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
        "    # threshold ndarray와 threshold에 따른 정밀도, 재현율 ndarray 추출.\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
        "    \n",
        "    # X축을 threshold값으로, Y축은 정밀로, 재현율 값으로 각각 plot 수행. 정밀도는 점선으로 표시 \n",
        "    plt.figure(figsize=(8,6))\n",
        "    threshold_boundary = thresholds.shape[0]\n",
        "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
        "    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
        "    \n",
        "    # threshold 값 X축의 Scale을 0.1 단위로 변경 \n",
        "    start, end = plt.xlim()\n",
        "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
        "    \n",
        "    # X축, Y축 label과 legend, 그리고 grid 설정 \n",
        "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
        "    plt.legend(); plt.grid()\n",
        "    plt.show()\n",
        "    \n",
        "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r6g1k6RpDWF"
      },
      "source": [
        "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train_over, ftr_test=X_test, tgt_train=y_train_over, tgt_test=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}