{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 10. Polynomial Regression.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMd/CQR8HNXO7ZofgZmZ/No",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KangSangKyu/BOOKSTUDY_Python-Machine-Learning-Perfect-Guide/blob/main/Chapter_10_Polynomial_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVwJzwFOeWZG"
      },
      "source": [
        "# 다항회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMAO8mM6LxG3"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import numpy as np \n",
        "\n",
        "# 다항식으로 변환한 단항식 생성, [[0,1], [2,3]]의 2x2 행렬 생성 \n",
        "\n",
        "X = np.arange(4).reshape(2,2)\n",
        "print('일차 단항식 계수 피처:\\n', X)\n",
        "\n",
        "# degree = 2인 2차 다항식으로 변환하기 위해 PolynomialFeatures를 이용해 변환 \n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "poly.fit(X)\n",
        "poly_ftr = poly.transform(X)\n",
        "print('변환된 2차 다항식 계수 피처:\\n', poly_ftr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2aQhNmuLxJV"
      },
      "source": [
        "def polynomial_func(X):\n",
        "    y = 1 + 2 * X + X ** 2 + X ** 3\n",
        "    return y\n",
        "\n",
        "X = np.arange(4).reshape(2,2)\n",
        "print('일차 단항식 계수값: \\n', X)\n",
        "\n",
        "y = polynomial_func(X)\n",
        "print('삼차 다항식 결정값: \\n', y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05YHo63PLxQT"
      },
      "source": [
        "# 3차 다항식 변환 \n",
        "\n",
        "poly_ftr = PolynomialFeatures(degree=3).fit_transform(X)\n",
        "print('3차 다항식 계수 feature: \\n', poly_ftr)\n",
        "\n",
        "# 선형 회귀에 3차 다항식 계수 피처와 3차 다항식 결정 값으로 학습 후 회귀 계수 확인 \n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(poly_ftr, y)\n",
        "\n",
        "print('Polynomial 회귀 계수\\n', np.round(model.coef_, 2))\n",
        "print('Polynomial 회귀 Shape :', model.coef_.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8aZwS9PL07n"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "def polynomial_func(X):\n",
        "    y = 1 + 2 * X + X ** 2 + X ** 3\n",
        "    return y\n",
        "\n",
        "# Pipeline 객체로 간소하게 다항식 피처 변환과 선형 회귀를 연결 \n",
        "\n",
        "model = Pipeline([('poly', PolynomialFeatures(degree=3)), ('linear', LinearRegression())])\n",
        "X = np.arange(4).reshape(2,2)\n",
        "y = polynomial_func(X)\n",
        "\n",
        "model = model.fit(X,y)\n",
        "print('Polynomial 회귀 계수 \\n', np.round(model.named_steps['linear'].coef_, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIzeEEwnL2H-"
      },
      "source": [
        "# 다항 회귀를 이용한 과소적합 및 과적합 \n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "%matplotlib inline\n",
        "\n",
        "# 임의의 값으로 구정된 X값에 대해 코사인 변환 값을 반환 \n",
        "\n",
        "def true_fun(X):\n",
        "    return np.cos(1.5 * np.pi * X)\n",
        "\n",
        "# X는 0부터 1까지 30개의 임의의 값을 순서대로 샘플링한 데이터 입니다.\n",
        "\n",
        "np.random.seed(0)\n",
        "n_samples = 30\n",
        "X = np.sort(np.random.rand(n_samples))\n",
        "\n",
        "# y 값은 코사인 기반의 true_fun()에서 약간의 노이즈 변동 값을 더한 값입니다. \n",
        "\n",
        "y = true_fun(X) + np.random.randn(n_samples) * 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M71jVdmTL3AF"
      },
      "source": [
        "plt.figure(figsize=(14,5))\n",
        "degrees = [1,4,15]\n",
        "\n",
        "# 다항 회귀의 차수를 1, 4, 15로 각각 변화시키면서 비교합니다. \n",
        "\n",
        "for i in range(len(degrees)):\n",
        "    ax = plt.subplot(1, len(degrees), i + 1)\n",
        "    plt.setp(ax, xticks=(), yticks=())\n",
        "    \n",
        "    # 개별 degree별로 Polynomial 변환합니다.\n",
        "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
        "    linear_regression = LinearRegression()\n",
        "    pipeline = Pipeline([('polynomial_features', polynomial_features), ('linear_regression', linear_regression)])\n",
        "    pipeline.fit(X.reshape(-1,1), y)\n",
        "    \n",
        "    # 교차 검증으로 다항 회귀를 평가합니다.\n",
        "    scores = cross_val_score(pipeline, X.reshape(-1,1), y, scoring='neg_mean_squared_error', cv=10)\n",
        "    \n",
        "    # Pipeline을 구성하는 세부 객체를 접근하는 named_steps['객체명']을 이용해 회귀계수 추출 \n",
        "    coefficients = pipeline.named_steps['linear_regression'].coef_\n",
        "    print('\\nDegree {0} 회귀 계수는 {1} 입니다.'.format(degrees[i], np.round(coefficients),2))\n",
        "    print('Degree {0} MSE 는 {1} 입니다.'.format(degrees[i], np.round(-1 * np.mean(scores),2)))\n",
        "    \n",
        "    # 0 부터 1 까지 테스트 데이터 세트를 100개로 나눠 예측을 수행합니다.\n",
        "    # 테스트 데이터 세트에 회귀 예측을 수행하고 예측 곡선과 실제 곡선을 그려서 비교합니다.\n",
        "    X_test = np.linspace(0,1,100)\n",
        "    \n",
        "    # 예측값 곡선\n",
        "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label='Model')\n",
        "    \n",
        "    # 실제값 곡선\n",
        "    plt.plot(X_test, true_fun(X_test), '--', label='True function')\n",
        "    plt.scatter(X,y, edgecolor='b', s=20, label='Samples')\n",
        "    \n",
        "    plt.xlabel('x'); plt.ylabel('y'); plt.xlim((0,1)); plt.ylim((-2,2)); plt.legend(loc='best')\n",
        "    plt.title('Degree {}\\nMSE = {:.2e}(+/-{:.2e})'.format(degrees[i], -scores.mean(), scores.std()))\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAjxgkCCL4NT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}